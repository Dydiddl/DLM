# Excel to SQLite Migration Guide

## ëª©ì°¨
1. [ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤€ë¹„](#ë§ˆì´ê·¸ë ˆì´ì…˜-ì¤€ë¹„)
2. [ë°ì´í„° ë¶„ì„](#ë°ì´í„°-ë¶„ì„)
3. [ìŠ¤í‚¤ë§ˆ ì„¤ê³„](#ìŠ¤í‚¤ë§ˆ-ì„¤ê³„)
4. [ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸](#ë§ˆì´ê·¸ë ˆì´ì…˜-ìŠ¤í¬ë¦½íŠ¸)
5. [ë°ì´í„° ê²€ì¦](#ë°ì´í„°-ê²€ì¦)
6. [í…ŒìŠ¤íŠ¸](#í…ŒìŠ¤íŠ¸)
7. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

## ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤€ë¹„

### í˜„ì¬ ìƒí™© ë¶„ì„
- **í˜„ì¬**: ì—‘ì…€ íŒŒì¼ì—ì„œ Lookup í•¨ìˆ˜ ì‚¬ìš©
- **ëª©í‘œ**: SQLite ë°ì´í„°ë² ì´ìŠ¤ë¡œ ì „í™˜
- **ì¥ì **: 
  - ë¹ ë¥¸ ê²€ìƒ‰ ë° í•„í„°ë§
  - ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥
  - í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ì—°ë™
  - ë°±ì—… ë° ë³µì› ìš©ì´

### í•„ìš”í•œ ë„êµ¬
```python
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd
import sqlite3
import numpy as np
from typing import Dict, List, Optional
import logging
```

## ë°ì´í„° ë¶„ì„

### ì—‘ì…€ íŒŒì¼ êµ¬ì¡° ë¶„ì„
```python
def analyze_excel_structure(excel_path: str, sheet_name: str = "Sheet1") -> Dict:
    """ì—‘ì…€ íŒŒì¼ êµ¬ì¡° ë¶„ì„"""
    try:
        df = pd.read_excel(excel_path, sheet_name=sheet_name)
        
        analysis = {
            'total_rows': len(df),
            'total_columns': len(df.columns),
            'columns': list(df.columns),
            'data_types': df.dtypes.to_dict(),
            'null_counts': df.isnull().sum().to_dict(),
            'duplicate_rows': df.duplicated().sum(),
            'sample_data': df.head(5).to_dict('records')
        }
        
        return analysis
    except Exception as e:
        print(f"ì—‘ì…€ íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return {}

# ì‚¬ìš© ì˜ˆì‹œ
analysis = analyze_excel_structure("workers.xlsx")
print("ì—‘ì…€ íŒŒì¼ ë¶„ì„ ê²°ê³¼:")
for key, value in analysis.items():
    print(f"{key}: {value}")
```

### ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
```python
def check_data_quality(df: pd.DataFrame) -> Dict:
    """ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬"""
    quality_report = {
        'missing_data': {},
        'duplicate_records': 0,
        'format_issues': {},
        'data_consistency': {}
    }
    
    # ëˆ„ë½ ë°ì´í„° í™•ì¸
    for column in df.columns:
        missing_count = df[column].isnull().sum()
        if missing_count > 0:
            quality_report['missing_data'][column] = missing_count
    
    # ì¤‘ë³µ ë ˆì½”ë“œ í™•ì¸
    quality_report['duplicate_records'] = df.duplicated().sum()
    
    # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ í˜•ì‹ ê²€ì‚¬
    if 'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸' in df.columns:
        invalid_ids = df[~df['ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸'].str.match(r'^\d{6}-\d{7}$', na=False)]
        quality_report['format_issues']['ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸'] = len(invalid_ids)
    
    # íœ´ëŒ€ì „í™”ë²ˆí˜¸ í˜•ì‹ ê²€ì‚¬
    if 'íœ´ëŒ€ì „í™”ë²ˆí˜¸' in df.columns:
        invalid_phones = df[~df['íœ´ëŒ€ì „í™”ë²ˆí˜¸'].str.match(r'^01[0-9]-\d{3,4}-\d{4}$', na=False)]
        quality_report['format_issues']['íœ´ëŒ€ì „í™”ë²ˆí˜¸'] = len(invalid_phones)
    
    return quality_report
```

## ìŠ¤í‚¤ë§ˆ ì„¤ê³„

### ê¸°ë³¸ í…Œì´ë¸” êµ¬ì¡°
```sql
-- íŒ€ í…Œì´ë¸”
CREATE TABLE teams (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT UNIQUE NOT NULL,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ê·¼ë¡œì í…Œì´ë¸”
CREATE TABLE workers (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    id_number TEXT UNIQUE NOT NULL,
    phone TEXT,
    team_id INTEGER,
    bank_account TEXT,
    safety_training BOOLEAN DEFAULT FALSE,
    notes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (team_id) REFERENCES teams(id) ON DELETE SET NULL
);

-- ë¬¸ì„œ í…Œì´ë¸”
CREATE TABLE documents (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    worker_id INTEGER NOT NULL,
    document_type TEXT NOT NULL CHECK (document_type IN ('id_card', 'bank_book')),
    file_path TEXT NOT NULL,
    file_name TEXT NOT NULL,
    uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (worker_id) REFERENCES workers(id) ON DELETE CASCADE
);

-- ê°ì‚¬ ë¡œê·¸ í…Œì´ë¸”
CREATE TABLE audit_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    operation TEXT NOT NULL,
    table_name TEXT NOT NULL,
    record_id INTEGER,
    old_values TEXT,
    new_values TEXT,
    user TEXT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### ì¸ë±ìŠ¤ ìƒì„±
```sql
-- ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì¸ë±ìŠ¤
CREATE INDEX idx_workers_name ON workers(name);
CREATE INDEX idx_workers_id_number ON workers(id_number);
CREATE INDEX idx_workers_team_id ON workers(team_id);
CREATE INDEX idx_workers_safety_training ON workers(safety_training);
CREATE INDEX idx_workers_created_at ON workers(created_at);
CREATE INDEX idx_documents_worker_id ON documents(worker_id);
CREATE INDEX idx_documents_type ON documents(document_type);
```

## ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

### ê¸°ë³¸ ë§ˆì´ê·¸ë ˆì´ì…˜ í´ë˜ìŠ¤
```python
class ExcelToSQLiteMigrator:
    def __init__(self, excel_path: str, db_path: str = "workers.db"):
        self.excel_path = excel_path
        self.db_path = db_path
        self.setup_logging()
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('migration.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def create_database_schema(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„±"""
        schema_queries = [
            # íŒ€ í…Œì´ë¸”
            """CREATE TABLE IF NOT EXISTS teams (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT UNIQUE NOT NULL,
                description TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )""",
            
            # ê·¼ë¡œì í…Œì´ë¸”
            """CREATE TABLE IF NOT EXISTS workers (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                id_number TEXT UNIQUE NOT NULL,
                phone TEXT,
                team_id INTEGER,
                bank_account TEXT,
                safety_training BOOLEAN DEFAULT FALSE,
                notes TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (team_id) REFERENCES teams(id) ON DELETE SET NULL
            )""",
            
            # ë¬¸ì„œ í…Œì´ë¸”
            """CREATE TABLE IF NOT EXISTS documents (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                worker_id INTEGER NOT NULL,
                document_type TEXT NOT NULL CHECK (document_type IN ('id_card', 'bank_book')),
                file_path TEXT NOT NULL,
                file_name TEXT NOT NULL,
                uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (worker_id) REFERENCES workers(id) ON DELETE CASCADE
            )""",
            
            # ê°ì‚¬ ë¡œê·¸ í…Œì´ë¸”
            """CREATE TABLE IF NOT EXISTS audit_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                operation TEXT NOT NULL,
                table_name TEXT NOT NULL,
                record_id INTEGER,
                old_values TEXT,
                new_values TEXT,
                user TEXT,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )"""
        ]
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            for query in schema_queries:
                cursor.execute(query)
            conn.commit()
        
        self.logger.info("ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„± ì™„ë£Œ")
    
    def create_indexes(self):
        """ì¸ë±ìŠ¤ ìƒì„±"""
        index_queries = [
            "CREATE INDEX IF NOT EXISTS idx_workers_name ON workers(name)",
            "CREATE INDEX IF NOT EXISTS idx_workers_id_number ON workers(id_number)",
            "CREATE INDEX IF NOT EXISTS idx_workers_team_id ON workers(team_id)",
            "CREATE INDEX IF NOT EXISTS idx_workers_safety_training ON workers(safety_training)",
            "CREATE INDEX IF NOT EXISTS idx_workers_created_at ON workers(created_at)",
            "CREATE INDEX IF NOT EXISTS idx_documents_worker_id ON documents(worker_id)",
            "CREATE INDEX IF NOT EXISTS idx_documents_type ON documents(document_type)"
        ]
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            for query in index_queries:
                cursor.execute(query)
            conn.commit()
        
        self.logger.info("ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
```

### ë°ì´í„° ë³€í™˜ ë° ë§ˆì´ê·¸ë ˆì´ì…˜
```python
def migrate_teams(self, df: pd.DataFrame) -> Dict[str, int]:
    """íŒ€ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
    team_mapping = {}
    
    # ê³ ìœ í•œ íŒ€ ëª©ë¡ ì¶”ì¶œ
    unique_teams = df['ì†Œì†íŒ€'].dropna().unique()
    
    with sqlite3.connect(self.db_path) as conn:
        cursor = conn.cursor()
        
        for team_name in unique_teams:
            if team_name and team_name.strip():
                try:
                    cursor.execute(
                        "INSERT INTO teams (name) VALUES (?)",
                        (team_name.strip(),)
                    )
                    team_id = cursor.lastrowid
                    team_mapping[team_name] = team_id
                    self.logger.info(f"íŒ€ ì¶”ê°€: {team_name} (ID: {team_id})")
                except sqlite3.IntegrityError:
                    # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŒ€ì¸ ê²½ìš° ID ì¡°íšŒ
                    cursor.execute("SELECT id FROM teams WHERE name = ?", (team_name.strip(),))
                    team_id = cursor.fetchone()[0]
                    team_mapping[team_name] = team_id
        
        conn.commit()
    
    return team_mapping

def migrate_workers(self, df: pd.DataFrame, team_mapping: Dict[str, int]):
    """ê·¼ë¡œì ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
    success_count = 0
    error_count = 0
    
    with sqlite3.connect(self.db_path) as conn:
        cursor = conn.cursor()
        
        for index, row in df.iterrows():
            try:
                # ë°ì´í„° ì •ì œ
                name = str(row['ì´ë¦„']).strip() if pd.notna(row['ì´ë¦„']) else None
                id_number = str(row['ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸']).strip() if pd.notna(row['ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸']) else None
                phone = str(row['íœ´ëŒ€ì „í™”ë²ˆí˜¸']).strip() if pd.notna(row['íœ´ëŒ€ì „í™”ë²ˆí˜¸']) else None
                team_name = str(row['ì†Œì†íŒ€']).strip() if pd.notna(row['ì†Œì†íŒ€']) else None
                bank_account = str(row['ê³„ì¢Œë²ˆí˜¸']).strip() if pd.notna(row['ê³„ì¢Œë²ˆí˜¸']) else None
                safety_training = bool(row['ì•ˆì „êµìœ¡']) if pd.notna(row['ì•ˆì „êµìœ¡']) else False
                notes = str(row['ë¹„ê³ ']).strip() if pd.notna(row['ë¹„ê³ ']) else None
                
                # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                if not name or not id_number:
                    self.logger.warning(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: í–‰ {index + 2}")
                    error_count += 1
                    continue
                
                # íŒ€ ID ë§¤í•‘
                team_id = team_mapping.get(team_name) if team_name else None
                
                # ê·¼ë¡œì ë°ì´í„° ì‚½ì…
                cursor.execute("""
                    INSERT INTO workers (name, id_number, phone, team_id, bank_account, safety_training, notes)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (name, id_number, phone, team_id, bank_account, safety_training, notes))
                
                success_count += 1
                
                if success_count % 100 == 0:
                    self.logger.info(f"ì§„í–‰ ìƒí™©: {success_count}ëª… ì²˜ë¦¬ ì™„ë£Œ")
                
            except sqlite3.IntegrityError as e:
                self.logger.error(f"ì¤‘ë³µ ë°ì´í„° ë˜ëŠ” ì œì•½ ì¡°ê±´ ìœ„ë°˜: í–‰ {index + 2}, ì˜¤ë¥˜: {e}")
                error_count += 1
            except Exception as e:
                self.logger.error(f"ë°ì´í„° ì‚½ì… ì˜¤ë¥˜: í–‰ {index + 2}, ì˜¤ë¥˜: {e}")
                error_count += 1
        
        conn.commit()
    
    self.logger.info(f"ê·¼ë¡œì ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: ì„±ê³µ {success_count}ëª…, ì‹¤íŒ¨ {error_count}ëª…")
    return success_count, error_count

def run_migration(self, sheet_name: str = "Sheet1"):
    """ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
    try:
        self.logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        
        # 1. ì—‘ì…€ íŒŒì¼ ì½ê¸°
        self.logger.info("ì—‘ì…€ íŒŒì¼ ì½ê¸° ì¤‘...")
        df = pd.read_excel(self.excel_path, sheet_name=sheet_name)
        self.logger.info(f"ì´ {len(df)}í–‰ì˜ ë°ì´í„° ì½ê¸° ì™„ë£Œ")
        
        # 2. ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
        self.logger.info("ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ ì¤‘...")
        quality_report = check_data_quality(df)
        self.logger.info(f"í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼: {quality_report}")
        
        # 3. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„±
        self.logger.info("ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„± ì¤‘...")
        self.create_database_schema()
        
        # 4. íŒ€ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        self.logger.info("íŒ€ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        team_mapping = self.migrate_teams(df)
        
        # 5. ê·¼ë¡œì ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
        self.logger.info("ê·¼ë¡œì ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        success_count, error_count = self.migrate_workers(df, team_mapping)
        
        # 6. ì¸ë±ìŠ¤ ìƒì„±
        self.logger.info("ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        self.create_indexes()
        
        # 7. ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ ë³´ê³ 
        self.logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        self.generate_migration_report(success_count, error_count, quality_report)
        
    except Exception as e:
        self.logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
```

## ë°ì´í„° ê²€ì¦

### ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ê²€ì¦
```python
def verify_migration(self) -> Dict:
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ê²€ì¦"""
    verification_results = {}
    
    with sqlite3.connect(self.db_path) as conn:
        cursor = conn.cursor()
        
        # 1. ì´ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM workers")
        worker_count = cursor.fetchone()[0]
        verification_results['total_workers'] = worker_count
        
        cursor.execute("SELECT COUNT(*) FROM teams")
        team_count = cursor.fetchone()[0]
        verification_results['total_teams'] = team_count
        
        # 2. íŒ€ë³„ ê·¼ë¡œì ìˆ˜ í™•ì¸
        cursor.execute("""
            SELECT t.name, COUNT(w.id) as worker_count
            FROM teams t
            LEFT JOIN workers w ON t.id = w.team_id
            GROUP BY t.id, t.name
            ORDER BY worker_count DESC
        """)
        team_stats = cursor.fetchall()
        verification_results['team_statistics'] = team_stats
        
        # 3. ì•ˆì „êµìœ¡ ì´ìˆ˜ì ìˆ˜ í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM workers WHERE safety_training = 1")
        trained_count = cursor.fetchone()[0]
        verification_results['safety_trained_count'] = trained_count
        
        # 4. ì¤‘ë³µ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ í™•ì¸
        cursor.execute("""
            SELECT id_number, COUNT(*) as count
            FROM workers
            GROUP BY id_number
            HAVING count > 1
        """)
        duplicates = cursor.fetchall()
        verification_results['duplicate_id_numbers'] = duplicates
        
        # 5. ë°ì´í„° ë¬´ê²°ì„± í™•ì¸
        cursor.execute("""
            SELECT COUNT(*) FROM workers w
            LEFT JOIN teams t ON w.team_id = t.id
            WHERE w.team_id IS NOT NULL AND t.id IS NULL
        """)
        orphaned_workers = cursor.fetchone()[0]
        verification_results['orphaned_workers'] = orphaned_workers
    
    return verification_results

def generate_migration_report(self, success_count: int, error_count: int, quality_report: Dict):
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ë³´ê³ ì„œ ìƒì„±"""
    verification_results = self.verify_migration()
    
    report = f"""
=== ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ ë³´ê³ ì„œ ===

ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼:
- ì„±ê³µ: {success_count}ëª…
- ì‹¤íŒ¨: {error_count}ëª…
- ì„±ê³µë¥ : {success_count/(success_count+error_count)*100:.1f}%

ğŸ“ˆ ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©:
- ì´ ê·¼ë¡œì: {verification_results['total_workers']}ëª…
- ì´ íŒ€: {verification_results['total_teams']}ê°œ
- ì•ˆì „êµìœ¡ ì´ìˆ˜ì: {verification_results['safety_trained_count']}ëª…

âš ï¸ ì£¼ì˜ì‚¬í•­:
- ì¤‘ë³µ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸: {len(verification_results['duplicate_id_numbers'])}ê±´
- ê³ ì•„ ë ˆì½”ë“œ: {verification_results['orphaned_workers']}ê±´

ğŸ“‹ í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼:
{quality_report}
"""
    
    # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
    with open('migration_report.txt', 'w', encoding='utf-8') as f:
        f.write(report)
    
    self.logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: migration_report.txt")
    print(report)
```

## í…ŒìŠ¤íŠ¸

### ë§ˆì´ê·¸ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸
```python
def test_migration(self):
    """ë§ˆì´ê·¸ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸"""
    # 1. ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    test_data = pd.DataFrame({
        'ì´ë¦„': ['í™ê¸¸ë™', 'ê¹€ì² ìˆ˜', 'ì´ì˜í¬'],
        'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸': ['123456-1234567', '234567-2345678', '345678-3456789'],
        'íœ´ëŒ€ì „í™”ë²ˆí˜¸': ['010-1234-5678', '010-2345-6789', '010-3456-7890'],
        'ì†Œì†íŒ€': ['ê±´ì„¤íŒ€', 'ê±´ì„¤íŒ€', 'ì „ê¸°íŒ€'],
        'ê³„ì¢Œë²ˆí˜¸': ['123-456-789', '234-567-890', '345-678-901'],
        'ì•ˆì „êµìœ¡': [True, False, True],
        'ë¹„ê³ ': ['í…ŒìŠ¤íŠ¸1', 'í…ŒìŠ¤íŠ¸2', 'í…ŒìŠ¤íŠ¸3']
    })
    
    # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
    test_db_path = "test_workers.db"
    test_migrator = ExcelToSQLiteMigrator("test.xlsx", test_db_path)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_migrator.create_database_schema()
    team_mapping = test_migrator.migrate_teams(test_data)
    success_count, error_count = test_migrator.migrate_workers(test_data, team_mapping)
    
    # ê²°ê³¼ ê²€ì¦
    verification_results = test_migrator.verify_migration()
    
    print("í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {error_count}")
    print(f"ê²€ì¦ ê²°ê³¼: {verification_results}")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬
    import os
    if os.path.exists(test_db_path):
        os.remove(test_db_path)
```

## ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²°ì±…

#### 1. ì¸ì½”ë”© ë¬¸ì œ
```python
def handle_encoding_issues(self, excel_path: str) -> pd.DataFrame:
    """ì¸ì½”ë”© ë¬¸ì œ í•´ê²°"""
    try:
        # UTF-8ë¡œ ì‹œë„
        return pd.read_excel(excel_path, encoding='utf-8')
    except UnicodeDecodeError:
        try:
            # CP949ë¡œ ì‹œë„
            return pd.read_excel(excel_path, encoding='cp949')
        except UnicodeDecodeError:
            # ê¸°ë³¸ ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„
            return pd.read_excel(excel_path)
```

#### 2. ë°ì´í„° íƒ€ì… ë³€í™˜ ë¬¸ì œ
```python
def clean_data_types(self, df: pd.DataFrame) -> pd.DataFrame:
    """ë°ì´í„° íƒ€ì… ì •ì œ"""
    # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
    date_columns = ['ë“±ë¡ì¼', 'ìˆ˜ì •ì¼']
    for col in date_columns:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors='coerce')
    
    # ìˆ«ì ì»¬ëŸ¼ ì²˜ë¦¬
    numeric_columns = ['ê¸‰ì—¬', 'ê·¼ë¬´ì‹œê°„']
    for col in numeric_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # ë¶ˆë¦° ì»¬ëŸ¼ ì²˜ë¦¬
    boolean_columns = ['ì•ˆì „êµìœ¡', 'í™œì„±ìƒíƒœ']
    for col in boolean_columns:
        if col in df.columns:
            df[col] = df[col].map({'Y': True, 'N': False, 'ì˜ˆ': True, 'ì•„ë‹ˆì˜¤': False})
            df[col] = df[col].fillna(False)
    
    return df
```

#### 3. ì¤‘ë³µ ë°ì´í„° ì²˜ë¦¬
```python
def handle_duplicates(self, df: pd.DataFrame) -> pd.DataFrame:
    """ì¤‘ë³µ ë°ì´í„° ì²˜ë¦¬"""
    # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ê¸°ì¤€ ì¤‘ë³µ ì œê±° (ìµœì‹  ë°ì´í„° ìœ ì§€)
    df = df.sort_values('ë“±ë¡ì¼', ascending=False)
    df = df.drop_duplicates(subset=['ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸'], keep='first')
    
    return df
```

### ë¡¤ë°± ë°©ë²•
```python
def rollback_migration(self):
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°±"""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ë°±ì—…
        import shutil
        from datetime import datetime
        
        backup_name = f"rollback_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
        shutil.copy2(self.db_path, backup_name)
        
        # ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ì‚­ì œ
        import os
        os.remove(self.db_path)
        
        self.logger.info(f"ë¡¤ë°± ì™„ë£Œ. ë°±ì—… íŒŒì¼: {backup_name}")
        return True
        
    except Exception as e:
        self.logger.error(f"ë¡¤ë°± ì¤‘ ì˜¤ë¥˜: {e}")
        return False
```

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼í•˜ë©´ ì—‘ì…€ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ SQLiteë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 